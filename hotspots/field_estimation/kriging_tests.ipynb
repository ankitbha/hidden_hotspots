{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8c6621e-2782-4469-95df-28ee8eed305e",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a008e40-3b8f-4c27-a0bf-a94789acc0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import pytz\n",
    "import argparse\n",
    "# import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from geopy import distance\n",
    "import datetime\n",
    "import tilemapbase\n",
    "from copy import deepcopy\n",
    "import pickle as pkl\n",
    "from PIL import Image\n",
    "import skimage.measure\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "os.environ['PYTHONWARNINGS']='ignore'\n",
    "import hyperopt\n",
    "from joblib import Parallel, delayed\n",
    "import random\n",
    "random.seed(42)\n",
    "import scipy\n",
    "import torch\n",
    "from pykrige.ok import OrdinaryKriging\n",
    "from pykrige.uk import UniversalKriging\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6941d3b4-2a15-4e80-9304-8bd1c1c66f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = 'combined'\n",
    "sensor = 'pm25'\n",
    "res_time = '1H'\n",
    "filepath_root = '/scratch/ab9738/pollution_with_sensors/'\n",
    "# spikes_file = filepath_root+'hotspots/spikes_combined_1H.csv'\n",
    "# time_high_file = filepath_root+'hotspots/hotspots_combined_temporalhigh_1H.pkl'\n",
    "# time_low_file = filepath_root+'hotspots/hotspots_combined_temporallow_1H.pkl'\n",
    "# space_high_file = filepath_root+'hotspots/hotspots_combined_spatialhigh_1H.pkl'\n",
    "# space_low_file = filepath_root+'hotspots/hotspots_combined_spatiallow_1H.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f9750d-7a81-4db1-8de9-545e74badb2f",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c784b837-f073-4c61-904a-21edec3d92df",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_data_kai = filepath_root+'data/kaiterra/kaiterra_fieldeggid_{}_current_panel.csv'.format(res_time)\n",
    "filepath_data_gov = filepath_root+'data/govdata/govdata_{}_current.csv'.format(res_time)\n",
    "filepath_locs_kai = filepath_root+'data/kaiterra/kaiterra_locations.csv'\n",
    "filepath_locs_gov = filepath_root+'data/govdata/govdata_locations.csv'\n",
    "\n",
    "locs_kai = pd.read_csv(filepath_locs_kai, index_col=[0])\n",
    "locs_kai['Type'] = 'Kaiterra'\n",
    "locs_gov = pd.read_csv(filepath_locs_gov, index_col=[0])\n",
    "locs_gov['Type'] = 'Govt'\n",
    "locs = pd.merge(locs_kai, locs_gov, how='outer',\\\n",
    "                on=['Monitor ID', 'Latitude', 'Longitude', 'Location', 'Type'], copy=False)\n",
    "data_kai = pd.read_csv(filepath_data_kai, index_col=[0,1], parse_dates=True)[sensor]\n",
    "data_gov = pd.read_csv(filepath_data_gov, index_col=[0,1], parse_dates=True)[sensor]\n",
    "data = pd.concat([data_kai, data_gov], axis=0, copy=False)\n",
    "\n",
    "start_dt = data.index.levels[1][0]\n",
    "end_dt = data.index.levels[1][-1]\n",
    "\n",
    "if start_dt.tzname != 'IST':\n",
    "        if start_dt.tzinfo is None:\n",
    "            start_dt = start_dt.tz_localize('UTC')\n",
    "        start_dt = start_dt.tz_convert(pytz.FixedOffset(330))\n",
    "    \n",
    "if end_dt.tzname != 'IST':\n",
    "    if end_dt.tzinfo is None: \n",
    "        end_dt = end_dt.tz_localize('UTC')\n",
    "    end_dt = end_dt.tz_convert(pytz.FixedOffset(330))\n",
    "\n",
    "# now, filter through the start and end dates\n",
    "data.sort_index(inplace=True)\n",
    "data = data.loc[(slice(None), slice(start_dt, end_dt))]\n",
    "\n",
    "if(source=='govdata'):\n",
    "    df = data_gov.unstack(level=0)\n",
    "elif(source=='kaiterra'):\n",
    "    df = data_kai.unstack(level=0)\n",
    "else:\n",
    "    df = data.unstack(level=0)\n",
    "distances = pd.read_csv('/scratch/ab9738/pollution_with_sensors/data/combined_distances.csv', index_col=[0])\n",
    "distances = distances.loc[df.columns, df.columns]\n",
    "distances[distances == 0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16f5b97-6cdd-415e-bf68-f02af3026628",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(0, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3fb65d-4b5e-46b6-aa00-bb5e2f1104e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f11dbf-eea2-4502-957f-c9781a67a5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "locs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de396ae3-27fa-46d0-8ef6-0a58693408f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "Finding random data point to test kriging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db167560-f39c-4b2e-8d7d-52003cf3c8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ape = []\n",
    "i = 0\n",
    "for idx, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "# random_ts = df.sample()\n",
    "    i+=1\n",
    "    # if(i==100):\n",
    "    #     break\n",
    "    x = locs.loc[df.columns]['Longitude'].values\n",
    "\n",
    "    y = locs.loc[df.columns]['Latitude'].values\n",
    "\n",
    "    z = row.values\n",
    "\n",
    "    x = x[~np.isnan(z)]\n",
    "    y = y[~np.isnan(z)]\n",
    "    z = z[~np.isnan(z)]\n",
    "    \n",
    "    if(len(x)<30):\n",
    "        continue\n",
    "\n",
    "    x_train, x_test, y_train, y_test, z_train, z_test = train_test_split(\n",
    "        x, y, z, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Do the kriging experiment\n",
    "\n",
    "    # OK = OrdinaryKriging(\n",
    "    #     x_train,\n",
    "    #     y_train,\n",
    "    #     z_train,\n",
    "    #     variogram_model=\"spherical\",\n",
    "    #     verbose=False,\n",
    "    #     enable_plotting=False,\n",
    "    # )\n",
    "    UK = UniversalKriging(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    z_train,\n",
    "    variogram_model=\"linear\",\n",
    "    drift_terms=[\"regional_linear\"],\n",
    "    )\n",
    "\n",
    "    z_pred, ss_pred = UK.execute(\"points\", x_test, y_test)\n",
    "    ape.append(np.abs((z_test-z_pred)/z_test))\n",
    "ape_arr = np.concatenate(ape)\n",
    "mape = np.mean(ape_arr)\n",
    "mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7fbaf1-5f22-4595-83b2-fddf7c4b369a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gridx = np.arange(76.85, 77.65, 0.01)\n",
    "# gridy = np.arange(28.2, 29.0, 0.01)\n",
    "\n",
    "# z_grid, ss_grid = OK_train.execute(\"grid\", gridx, gridy[::-1])\n",
    "\n",
    "# plt.imshow(z_grid)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa179664-5899-42fe-9d8a-76a1362009b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8227ce9f-4c5e-4d97-9782-a74b70a7db41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
