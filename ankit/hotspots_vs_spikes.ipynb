{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18d6ae1b",
   "metadata": {},
   "source": [
    "# Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5149540",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import pytz\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from geopy import distance\n",
    "import datetime\n",
    "import tilemapbase\n",
    "from copy import deepcopy\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c29cfd",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15899c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = 'combined'\n",
    "sensor = 'pm25'\n",
    "res_time = '3H'\n",
    "filepath_root = '/scratch/ab9738/epod-nyu-delhi-pollution/'\n",
    "spikes_file = filepath_root+'ankit/spikes.csv'\n",
    "time_high_file = filepath_root+'ankit/time_high_3H.pkl'\n",
    "time_low_file = filepath_root+'ankit/time_low_3H.pkl'\n",
    "space_high_file = filepath_root+'ankit/space_high_3H.pkl'\n",
    "space_low_file = filepath_root+'ankit/space_low_3H.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ce287d",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577f0494",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_data_kai = filepath_root+'data/kaiterra/kaiterra_fieldeggid_{}_current_panel.csv'.format(res_time)\n",
    "filepath_data_gov = filepath_root+'data/govdata/govdata_{}_current.csv'.format(res_time)\n",
    "filepath_locs_kai = filepath_root+'data/kaiterra/kaiterra_locations.csv'\n",
    "filepath_locs_gov = filepath_root+'data/govdata/govdata_locations.csv'\n",
    "\n",
    "locs_kai = pd.read_csv(filepath_locs_kai, index_col=[0])\n",
    "locs_kai['Type'] = 'Kaiterra'\n",
    "locs_gov = pd.read_csv(filepath_locs_gov, index_col=[0])\n",
    "locs_gov['Type'] = 'Govt'\n",
    "locs = pd.merge(locs_kai, locs_gov, how='outer',\\\n",
    "                on=['Monitor ID', 'Latitude', 'Longitude', 'Location', 'Type'], copy=False)\n",
    "data_kai = pd.read_csv(filepath_data_kai, index_col=[0,1], parse_dates=True)[sensor]\n",
    "data_gov = pd.read_csv(filepath_data_gov, index_col=[0,1], parse_dates=True)[sensor]\n",
    "data = pd.concat([data_kai, data_gov], axis=0, copy=False)\n",
    "\n",
    "start_dt = data.index.levels[1][0]\n",
    "end_dt = data.index.levels[1][-1]\n",
    "\n",
    "if start_dt.tzname != 'IST':\n",
    "        if start_dt.tzinfo is None:\n",
    "            start_dt = start_dt.tz_localize('UTC')\n",
    "        start_dt = start_dt.tz_convert(pytz.FixedOffset(330))\n",
    "    \n",
    "if end_dt.tzname != 'IST':\n",
    "    if end_dt.tzinfo is None: \n",
    "        end_dt = end_dt.tz_localize('UTC')\n",
    "    end_dt = end_dt.tz_convert(pytz.FixedOffset(330))\n",
    "\n",
    "# now, filter through the start and end dates\n",
    "data.sort_index(inplace=True)\n",
    "data = data.loc[(slice(None), slice(start_dt, end_dt))]\n",
    "\n",
    "if(source=='govdata'):\n",
    "    df = data_gov.unstack(level=0)\n",
    "elif(source=='kaiterra'):\n",
    "    df = data_kai.unstack(level=0)\n",
    "else:\n",
    "    df = data.unstack(level=0)\n",
    "distances = pd.read_csv('/scratch/ab9738/epod-nyu-delhi-pollution/data/combined_distances.csv', index_col=[0])\n",
    "distances = distances.loc[df.columns, df.columns]\n",
    "distances[distances == 0] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31186d1",
   "metadata": {},
   "source": [
    "# Load Spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a18adca",
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes = pd.read_csv(spikes_file, index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9adfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "(spikes==900).sum().sum()+(spikes==910).sum().sum()+(spikes==990).sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69e2a89",
   "metadata": {},
   "source": [
    "# Load Temporal Hotspots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7398137b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(time_low_file,'rb') as file:\n",
    "    thsp_low = pkl.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bcf02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(time_high_file,'rb') as file:\n",
    "    thsp_high = pkl.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f0c464",
   "metadata": {},
   "source": [
    "# Temporal High"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f61500",
   "metadata": {},
   "outputs": [],
   "source": [
    "win_size = []\n",
    "for col in df.columns:\n",
    "    for i in range(len(thsp_high[col])):\n",
    "        win_size.append(len(thsp_high[col][i][2]))   \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "stats = plt.hist(win_size, weights=np.ones(len(win_size))/len(win_size), \\\n",
    "                 bins=range(int(min(win_size)),int(max(win_size)) + 1, 1), cumulative=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1988f977",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_list = []\n",
    "for col in df.columns:\n",
    "    for entry in thsp_high[col]:\n",
    "        time_list.append(entry[0].time().hour)\n",
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "stats = plt.hist(time_list, weights=np.ones(len(time_list))/len(time_list), \\\n",
    "                 bins=range(int(min(time_list)),int(max(time_list)) + 1, 1), cumulative=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b438fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_height = []\n",
    "for col in df.columns:\n",
    "    ohsp_index = list(spikes[spikes[col]==900].index) + \\\n",
    "    list(spikes[spikes[col]==910].index) + \\\n",
    "    list(spikes[spikes[col]==990].index)\n",
    "    for ind in ohsp_index:\n",
    "        ts_after = ind + datetime.timedelta(hours=3)\n",
    "        ts_before = ind - datetime.timedelta(hours=3)\n",
    "        val = df[col].loc[ind]\n",
    "        val_before = df[col].loc[ts_before]\n",
    "        val_after = df[col].loc[ts_after]\n",
    "        old_height.append(val - min(val_before, val_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50e028a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_height = []\n",
    "for col in list(df.columns):\n",
    "    for i in range(len(thsp_high[col])):\n",
    "        val_before = df[col].loc[thsp_high[col][i][2][0]]\n",
    "        val_after = df[col].loc[thsp_high[col][i][2][-1]]\n",
    "        val = thsp_high[col][i][1]\n",
    "        new_height.append(val - min(val_before, val_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37de593c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,7))\n",
    "stats_old = plt.hist(old_height, weights=np.ones(len(old_height))/len(old_height), \\\n",
    "                 bins=range(int(min(old_height)),int(max(old_height)) + 1, 1), cumulative=False, alpha=0.5,\\\n",
    "                     label='Old Algorithm')\n",
    "stats_new = plt.hist(new_height, weights=np.ones(len(new_height))/len(new_height), \\\n",
    "                 bins=range(int(min(new_height)),int(max(new_height)) + 1, 1), cumulative=False, alpha=0.5, \\\n",
    "                    label='New Algorithm')\n",
    "plt.title('Height Distribution')\n",
    "plt.ylabel('PDF')\n",
    "plt.xlabel('Height of hospots from base')\n",
    "plt.legend()\n",
    "plt.savefig(\"temp_height_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2511b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_temp = {}\n",
    "for col in df.columns:\n",
    "    matching_temp[col] = []\n",
    "    ohsp_index = list(spikes[spikes[col]==900].index) + \\\n",
    "    list(spikes[spikes[col]==910].index) + \\\n",
    "    list(spikes[spikes[col]==990].index)\n",
    "    for ind in ohsp_index:\n",
    "        for i in range(len(thsp_high[col])):\n",
    "            if(ind > thsp_high[col][i][2][0] and ind < thsp_high[col][i][2][-1]):\n",
    "                matching_temp[col].append([thsp_high[col][i][0], ind])\n",
    "\n",
    "num_match = 0\n",
    "for col in df.columns:\n",
    "    num_match += len(matching_temp[col])\n",
    "num_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d61308f",
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92419a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(thsp_high['113E'])\n",
    "viz_data = arr[arr[:,0]==matching_temp['113E'][2][0]]\n",
    "df['113E'].loc[viz_data[0][2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299cd6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['113E'].loc[viz_data[0][2]].index.to_numpy()\n",
    "ts_before = matching_temp['113E'][2][1] - datetime.timedelta(hours=3)\n",
    "ts_after = matching_temp['113E'][2][1] + datetime.timedelta(hours=3)\n",
    "x_or = np.array([ts_before, matching_temp['113E'][2][1], ts_after])\n",
    "y_or = np.array([df['113E'].loc[ts_before], df['113E'].loc[matching_temp['113E'][2][1]], df['113E'].loc[ts_after]])\n",
    "y = df['113E'].loc[viz_data[0][2]].to_numpy()\n",
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "plt.title('Temporal Hotspot Instance: '+str(x[0].date())+'__'+str(x[-1].date()) + \" (113E)\")\n",
    "for i in range(len(x)):\n",
    "    x[i] = str(x[i].date().day) + '_' + str(x[i].time())[:-3]\n",
    "for i in range(len(x_or)):\n",
    "    x_or[i] = str(x_or[i].date().day) + '_' + str(x_or[i].time())[:-3]\n",
    "plt.plot(x,y,label='New Algorithm')\n",
    "plt.plot(x_or,y_or,label='Old Algorithm',color='r',alpha=0.5)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('PM2.5')\n",
    "plt.legend()\n",
    "plt.savefig('temporal_comp.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d03809",
   "metadata": {},
   "source": [
    "# Temporal Low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc6789d",
   "metadata": {},
   "outputs": [],
   "source": [
    "win_size = []\n",
    "for col in df.columns:\n",
    "    for i in range(len(thsp_low[col])):\n",
    "        win_size.append(len(thsp_low[col][i][2]))   \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "stats = plt.hist(win_size, weights=np.ones(len(win_size))/len(win_size), \\\n",
    "                 bins=range(int(min(win_size)),int(max(win_size)) + 1, 1), cumulative=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d74bf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_list = []\n",
    "for col in df.columns:\n",
    "    for entry in thsp_low[col]:\n",
    "        time_list.append(entry[0].time().hour)\n",
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "stats = plt.hist(time_list, weights=np.ones(len(time_list))/len(time_list), \\\n",
    "                 bins=range(int(min(time_list)),int(max(time_list)) + 1, 1), cumulative=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89479f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_height = []\n",
    "for col in df.columns:\n",
    "    ohsp_index = list(spikes[spikes[col]==100].index) + \\\n",
    "    list(spikes[spikes[col]==110].index) + \\\n",
    "    list(spikes[spikes[col]==190].index)\n",
    "    for ind in ohsp_index:\n",
    "        ts_after = ind + datetime.timedelta(hours=3)\n",
    "        ts_before = ind - datetime.timedelta(hours=3)\n",
    "        val = df[col].loc[ind]\n",
    "        val_before = df[col].loc[ts_before]\n",
    "        val_after = df[col].loc[ts_after]\n",
    "        old_height.append(val - min(val_before, val_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3957db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_height = []\n",
    "for col in list(df.columns):\n",
    "    for i in range(len(thsp_low[col])):\n",
    "        val_before = df[col].loc[thsp_low[col][i][2][0]]\n",
    "        val_after = df[col].loc[thsp_low[col][i][2][-1]]\n",
    "        val = thsp_low[col][i][1]\n",
    "        new_height.append(val - min(val_before, val_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70f85b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,7))\n",
    "stats_old = plt.hist(old_height, weights=np.ones(len(old_height))/len(old_height), \\\n",
    "                 bins=range(int(min(old_height)),int(max(old_height)) + 1, 1), cumulative=False, alpha=0.5,\\\n",
    "                     label='Old Algorithm')\n",
    "stats_new = plt.hist(new_height, weights=np.ones(len(new_height))/len(new_height), \\\n",
    "                 bins=range(int(min(new_height)),int(max(new_height)) + 1, 1), cumulative=False, alpha=0.5, \\\n",
    "                    label='New Algorithm')\n",
    "plt.title('Height Distribution')\n",
    "plt.ylabel('PDF')\n",
    "plt.xlabel('Height of hospots from base')\n",
    "plt.legend()\n",
    "plt.savefig(\"temp_height_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844ced8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_temp = {}\n",
    "for col in df.columns:\n",
    "    matching_temp[col] = []\n",
    "    ohsp_index = list(spikes[spikes[col]==100].index) + \\\n",
    "    list(spikes[spikes[col]==110].index) + \\\n",
    "    list(spikes[spikes[col]==190].index)\n",
    "    for ind in ohsp_index:\n",
    "        for i in range(len(thsp_low[col])):\n",
    "            if(ind > thsp_low[col][i][2][0] and ind < thsp_low[col][i][2][-1]):\n",
    "                matching_temp[col].append([thsp_low[col][i][0], ind])\n",
    "\n",
    "num_match = 0\n",
    "for col in df.columns:\n",
    "    num_match += len(matching_temp[col])\n",
    "num_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7399a00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matching_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a767284",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(thsp_low['4BE7'])\n",
    "viz_data = arr[arr[:,0]==matching_temp['4BE7'][2][0]]\n",
    "df['4BE7'].loc[viz_data[0][2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea558c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['4BE7'].loc[viz_data[0][2]].index.to_numpy()\n",
    "ts_before = matching_temp['4BE7'][2][1] - datetime.timedelta(hours=3)\n",
    "ts_after = matching_temp['4BE7'][2][1] + datetime.timedelta(hours=3)\n",
    "x_or = np.array([ts_before, matching_temp['4BE7'][2][1], ts_after])\n",
    "y_or = np.array([df['4BE7'].loc[ts_before], df['4BE7'].loc[matching_temp['4BE7'][2][1]], df['4BE7'].loc[ts_after]])\n",
    "y = df['4BE7'].loc[viz_data[0][2]].to_numpy()\n",
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "plt.title('Temporal Hotspot Instance: '+str(x[0].date())+'__'+str(x[-1].date()) + \" (113E)\")\n",
    "for i in range(len(x)):\n",
    "    x[i] = str(x[i].date().day) + '_' + str(x[i].time())[:-3]\n",
    "for i in range(len(x_or)):\n",
    "    x_or[i] = str(x_or[i].date().day) + '_' + str(x_or[i].time())[:-3]\n",
    "plt.plot(x,y,label='New Algorithm')\n",
    "plt.plot(x_or,y_or,label='Old Algorithm',color='r',alpha=0.5)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('PM2.5')\n",
    "plt.legend()\n",
    "plt.savefig('temporal_comp.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e95e45",
   "metadata": {},
   "source": [
    "# Load Spatial Hotspots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad1e2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(space_high_file,'rb') as file:\n",
    "    shsp_high = pkl.load(file)\n",
    "with open(space_low_file,'rb') as file:\n",
    "    shsp_low = pkl.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a76381b",
   "metadata": {},
   "source": [
    "# Spatial High"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f188f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "(spikes==90).sum().sum() + (spikes==990).sum().sum() + (spikes==190).sum().sum() +\\\n",
    "(spikes==99).sum().sum() + (spikes==91).sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcf1a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shsp_high_arr = np.array(shsp_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa512bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_dict = {}\n",
    "for col in df.columns:\n",
    "    dist_df = distances.loc[col].sort_values().dropna()\n",
    "    nn_dict[col] = dist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90f4ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "matching = []\n",
    "for idx in tqdm(df.index):\n",
    "    hsps = list(spikes.loc[idx][spikes.loc[idx]==90].index) + \\\n",
    "    list(spikes.loc[idx][spikes.loc[idx]==990].index) + \\\n",
    "    list(spikes.loc[idx][spikes.loc[idx]==190].index) + \\\n",
    "    list(spikes.loc[idx][spikes.loc[idx]==99].index) + \\\n",
    "    list(spikes.loc[idx][spikes.loc[idx]==19].index)\n",
    "    entry = shsp_high_arr[shsp_high_arr[:,0]==idx]\n",
    "    if(entry.size):\n",
    "        hsp = entry[0][1]\n",
    "        hsp_set = deepcopy(entry[0][2])\n",
    "        hsp_set.append(hsp)\n",
    "        set_new = set(hsp_set)\n",
    "        hsp_set.remove(hsp)\n",
    "        for i in hsps:\n",
    "            list_nn = list(nn_dict[i][nn_dict[i]<wsr*1000].index)\n",
    "            list_nn.append(i)\n",
    "            set_old = set(list_nn)\n",
    "            list_nn.remove(i)\n",
    "            if(set_new.intersection(set_old)):\n",
    "                matching.append([idx, hsp, hsp_set, i, list_nn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b6cb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(matching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6672265f",
   "metadata": {},
   "outputs": [],
   "source": [
    "matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6b4489",
   "metadata": {},
   "outputs": [],
   "source": [
    "matching[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab753f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hsp_new = locs.loc[[matching[3][1]]+matching[3][2]]\n",
    "hsp_old = locs.loc[[matching[3][3]]+matching[3][4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f59361",
   "metadata": {},
   "outputs": [],
   "source": [
    "hsp_new['Type'] = 'New'\n",
    "hsp_old['Type'] = 'Old'\n",
    "inter = set(hsp_new.index).intersection(set(hsp_old.index))\n",
    "hsp_new['Type'].loc[inter] = 'Both'\n",
    "hsp_old['Type'].loc[inter] = 'Both'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4298d1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "locs_map = pd.concat([hsp_new,hsp_old])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f325a35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_lims = locs.Latitude.min(), locs.Latitude.max()\n",
    "lon_lims = locs.Longitude.min(), locs.Longitude.max()\n",
    "lon_center, lat_center = locs.Longitude.mean(), locs.Latitude.mean()\n",
    "\n",
    "print(lat_lims)\n",
    "print(lon_lims)\n",
    "print(lat_center, lon_center)\n",
    "\n",
    "lat_pad = 1.1 * max(lat_center - lat_lims[0], lat_lims[1] - lat_center)\n",
    "lon_pad = 1.1 * max(lon_center - lon_lims[0], lon_lims[1] - lon_center)\n",
    "    \n",
    "extent = tilemapbase.Extent.from_lonlat(lon_center - lon_pad, \n",
    "                                        lon_center + lon_pad, \n",
    "                                        lat_center - lat_pad, \n",
    "                                        lat_center + lat_pad)\n",
    "# extent = tilemapbase.Extent.from_lonlat(lon_lims[0], lon_lims[1], lat_lims[0], lat_lims[1])\n",
    "\n",
    "# extent = extent.to_aspect(1.0)\n",
    "extent_proj = extent.to_project_3857\n",
    "\n",
    "# use openstreetmap (OSM)\n",
    "t = tilemapbase.tiles.Stamen_Toner_Background\n",
    "# t = tilemapbase.tiles.Stamen_Toner\n",
    "\n",
    "colordict = {'Kaiterra':'r', 'Govt':'b'}\n",
    "\n",
    "plt.rc('font', size=20)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,12), dpi=200)\n",
    "ax.xaxis.set_visible(False)\n",
    "ax.yaxis.set_visible(False)\n",
    "\n",
    "plotter = tilemapbase.Plotter(extent, t, width=600)\n",
    "plotter.plot(ax, t)\n",
    "\n",
    "for row in locs_map.itertuples():\n",
    "    x, y = tilemapbase.project(row.Longitude, row.Latitude)\n",
    "    if row.Type == 'New':\n",
    "        obj1 = ax.scatter(x, y, marker='.', color='r', s=400, label='New Algorithm')\n",
    "    elif row.Type == 'Old':\n",
    "        obj2 = ax.scatter(x, y, marker='.', color='b', s=400, label='Old Algorithm')\n",
    "    else:\n",
    "        obj3 = ax.scatter(x, y, marker='.', color='g', s=400, label='Intersection')\n",
    "    # ax.text(x, y, row._3[:2], fontsize=12, color='b', withdash=True)\n",
    "    ax.text(x, y, row.Index+'('+str(round(df.loc[matching[3][0]][row.Index],3))+')', fontsize=6)\n",
    "\n",
    "ax.legend((obj1, obj2, obj3), (obj1.get_label(), obj2.get_label(), obj3.get_label()), loc='lower right', ncol=3)\n",
    "# fig.savefig('locs_map.pdf')\n",
    "plt.title(\"Spatial Hotspot Instance: \"+str(matching[3][0]))\n",
    "plt.savefig('spatial_comp.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2d9fef",
   "metadata": {},
   "source": [
    "# Spatial Low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3692e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(spikes==10).sum().sum() + (spikes==910).sum().sum() + (spikes==110).sum().sum() +\\\n",
    "(spikes==19).sum().sum() + (spikes==11).sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e935241",
   "metadata": {},
   "outputs": [],
   "source": [
    "shsp_low_arr = np.array(shsp_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad9d847",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_dict = {}\n",
    "for col in df.columns:\n",
    "    dist_df = distances.loc[col].sort_values().dropna()\n",
    "    nn_dict[col] = dist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244d0b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "matching = []\n",
    "for idx in tqdm(df.index):\n",
    "    hsps = list(spikes.loc[idx][spikes.loc[idx]==10].index) + \\\n",
    "    list(spikes.loc[idx][spikes.loc[idx]==910].index) + \\\n",
    "    list(spikes.loc[idx][spikes.loc[idx]==110].index) + \\\n",
    "    list(spikes.loc[idx][spikes.loc[idx]==91].index) + \\\n",
    "    list(spikes.loc[idx][spikes.loc[idx]==11].index)\n",
    "    entry = shsp_low_arr[shsp_low_arr[:,0]==idx]\n",
    "    if(entry.size):\n",
    "        hsp = entry[0][1]\n",
    "        hsp_set = deepcopy(entry[0][2])\n",
    "        hsp_set.append(hsp)\n",
    "        set_new = set(hsp_set)\n",
    "        hsp_set.remove(hsp)\n",
    "        for i in hsps:\n",
    "            list_nn = list(nn_dict[i][nn_dict[i]<wsr*1000].index)\n",
    "            list_nn.append(i)\n",
    "            set_old = set(list_nn)\n",
    "            list_nn.remove(i)\n",
    "            if(set_new.intersection(set_old)):\n",
    "                matching.append([idx, hsp, hsp_set, i, list_nn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cad5c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(matching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d898fdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb62c98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "matching[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe97036",
   "metadata": {},
   "outputs": [],
   "source": [
    "hsp_new = locs.loc[[matching[0][1]]+matching[0][2]]\n",
    "hsp_old = locs.loc[[matching[0][3]]+matching[0][4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594c753f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hsp_new['Type'] = 'New'\n",
    "hsp_old['Type'] = 'Old'\n",
    "inter = set(hsp_new.index).intersection(set(hsp_old.index))\n",
    "hsp_new['Type'].loc[inter] = 'Both'\n",
    "hsp_old['Type'].loc[inter] = 'Both'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4443db",
   "metadata": {},
   "outputs": [],
   "source": [
    "locs_map = pd.concat([hsp_new,hsp_old])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8026f797",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_lims = locs.Latitude.min(), locs.Latitude.max()\n",
    "lon_lims = locs.Longitude.min(), locs.Longitude.max()\n",
    "lon_center, lat_center = locs.Longitude.mean(), locs.Latitude.mean()\n",
    "\n",
    "print(lat_lims)\n",
    "print(lon_lims)\n",
    "print(lat_center, lon_center)\n",
    "\n",
    "lat_pad = 1.1 * max(lat_center - lat_lims[0], lat_lims[1] - lat_center)\n",
    "lon_pad = 1.1 * max(lon_center - lon_lims[0], lon_lims[1] - lon_center)\n",
    "    \n",
    "extent = tilemapbase.Extent.from_lonlat(lon_center - lon_pad, \n",
    "                                        lon_center + lon_pad, \n",
    "                                        lat_center - lat_pad, \n",
    "                                        lat_center + lat_pad)\n",
    "# extent = tilemapbase.Extent.from_lonlat(lon_lims[0], lon_lims[1], lat_lims[0], lat_lims[1])\n",
    "\n",
    "# extent = extent.to_aspect(1.0)\n",
    "extent_proj = extent.to_project_3857\n",
    "\n",
    "# use openstreetmap (OSM)\n",
    "t = tilemapbase.tiles.Stamen_Toner_Background\n",
    "# t = tilemapbase.tiles.Stamen_Toner\n",
    "\n",
    "colordict = {'Kaiterra':'r', 'Govt':'b'}\n",
    "\n",
    "plt.rc('font', size=20)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,12), dpi=200)\n",
    "ax.xaxis.set_visible(False)\n",
    "ax.yaxis.set_visible(False)\n",
    "\n",
    "plotter = tilemapbase.Plotter(extent, t, width=600)\n",
    "plotter.plot(ax, t)\n",
    "\n",
    "for row in locs_map.itertuples():\n",
    "    x, y = tilemapbase.project(row.Longitude, row.Latitude)\n",
    "    if row.Type == 'New':\n",
    "        obj1 = ax.scatter(x, y, marker='.', color='r', s=400, label='New Algorithm')\n",
    "    elif row.Type == 'Old':\n",
    "        obj2 = ax.scatter(x, y, marker='.', color='b', s=400, label='Old Algorithm')\n",
    "    else:\n",
    "        obj3 = ax.scatter(x, y, marker='.', color='g', s=400, label='Intersection')\n",
    "    # ax.text(x, y, row._3[:2], fontsize=12, color='b', withdash=True)\n",
    "    ax.text(x, y, row.Index+'('+str(round(df.loc[matching[0][0]][row.Index],3))+')', fontsize=6)\n",
    "\n",
    "ax.legend((obj1, obj2, obj3), (obj1.get_label(), obj2.get_label(), obj3.get_label()), loc='lower right', ncol=3)\n",
    "# fig.savefig('locs_map.pdf')\n",
    "plt.title(\"Spatial Hotspot Instance: \"+str(matching[0][0]))\n",
    "plt.savefig('spatial_comp.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b354c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
