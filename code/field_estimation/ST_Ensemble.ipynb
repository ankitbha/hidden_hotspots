{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "760efbff-41b2-41f3-9836-1c40bb63a33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pytz\n",
    "import argparse\n",
    "# import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ioff()\n",
    "from tqdm import tqdm\n",
    "from geopy import distance\n",
    "import datetime\n",
    "import tilemapbase\n",
    "from copy import deepcopy\n",
    "import pickle as pkl\n",
    "from PIL import Image\n",
    "import skimage.measure\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "os.environ['PYTHONWARNINGS']='ignore'\n",
    "import hyperopt\n",
    "from joblib import Parallel, delayed\n",
    "import random\n",
    "random.seed(42)\n",
    "import scipy\n",
    "import torch\n",
    "from pykrige.ok import OrdinaryKriging\n",
    "from pykrige.ok3d import OrdinaryKriging3D\n",
    "from pykrige.uk import UniversalKriging\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.interpolate import CubicSpline\n",
    "import scipy.ndimage\n",
    "import scipy.stats\n",
    "import scipy.optimize\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bd2dd0-3c03-45e6-a7b8-96346f01e454",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d298a535-9c83-4bd7-a3f3-40df97e130c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = 'combined'\n",
    "sensor = 'pm25'\n",
    "res_time = '1H'\n",
    "filepath_root = '/scratch/ab9738/pollution_with_sensors/'\n",
    "\n",
    "filepath_data_kai = filepath_root+'data/kaiterra/kaiterra_fieldeggid_{}_current_panel.csv'.format(res_time)\n",
    "filepath_data_gov = filepath_root+'data/govdata/govdata_{}_current.csv'.format(res_time)\n",
    "filepath_locs_kai = filepath_root+'data/kaiterra/kaiterra_locations.csv'\n",
    "filepath_locs_gov = filepath_root+'data/govdata/govdata_locations.csv'\n",
    "\n",
    "locs_kai = pd.read_csv(filepath_locs_kai, index_col=[0])\n",
    "locs_kai['Type'] = 'Kaiterra'\n",
    "locs_gov = pd.read_csv(filepath_locs_gov, index_col=[0])\n",
    "locs_gov['Type'] = 'Govt'\n",
    "locs = pd.merge(locs_kai, locs_gov, how='outer',\\\n",
    "                on=['Monitor ID', 'Latitude', 'Longitude', 'Location', 'Type'], copy=False)\n",
    "data_kai = pd.read_csv(filepath_data_kai, index_col=[0,1], parse_dates=True)[sensor]\n",
    "data_gov = pd.read_csv(filepath_data_gov, index_col=[0,1], parse_dates=True)[sensor]\n",
    "data = pd.concat([data_kai, data_gov], axis=0, copy=False)\n",
    "data.replace(0,np.nan,inplace=True)\n",
    "\n",
    "start_dt = data.index.levels[1][0]\n",
    "end_dt = data.index.levels[1][-1]\n",
    "\n",
    "if start_dt.tzname != 'IST':\n",
    "        if start_dt.tzinfo is None:\n",
    "            start_dt = start_dt.tz_localize('UTC')\n",
    "        start_dt = start_dt.tz_convert(pytz.FixedOffset(330))\n",
    "    \n",
    "if end_dt.tzname != 'IST':\n",
    "    if end_dt.tzinfo is None: \n",
    "        end_dt = end_dt.tz_localize('UTC')\n",
    "    end_dt = end_dt.tz_convert(pytz.FixedOffset(330))\n",
    "\n",
    "# now, filter through the start and end dates\n",
    "data.sort_index(inplace=True)\n",
    "data = data.loc[(slice(None), slice(start_dt, end_dt))]\n",
    "\n",
    "if(source=='govdata'):\n",
    "    df = data_gov.unstack(level=0)\n",
    "elif(source=='kaiterra'):\n",
    "    df = data_kai.unstack(level=0)\n",
    "else:\n",
    "    df = data.unstack(level=0)\n",
    "distances = pd.read_csv('/scratch/ab9738/pollution_with_sensors/data/combined_distances.csv', index_col=[0])\n",
    "distances = distances.loc[df.columns, df.columns]\n",
    "distances[distances == 0] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b563724-65eb-4553-82b5-1120ead6fe03",
   "metadata": {},
   "source": [
    "# Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "75c2a5e5-8cb4-4870-811f-df06f3231b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "spline_cols = df.columns # columns needed for creating spline_df\n",
    "df['Pusa_IMD'] = (df['Pusa_IMD'] + df['Pusa_DPCC'])/2\n",
    "df['Pusa_DPCC'] = (df['Pusa_IMD'] + df['Pusa_DPCC'])/2\n",
    "df = np.log(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc8088c-aff5-4af4-948d-a563ca7bd6be",
   "metadata": {},
   "source": [
    "# Load Wind Speeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e3154555-0177-4f55-a290-4925b1a01722",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ws = pd.read_csv('/scratch/ab9738/pollution_with_sensors/hotspots/source_apportionment/wind_speeds.csv', parse_dates=True)\n",
    "df_ws = df_ws.sort_values(['Timestamp']).reset_index(drop=True)\n",
    "df_ws = df_ws.set_index(pd.DatetimeIndex(df_ws['Timestamp']))\n",
    "df_ws = df_ws[['u-component', 'v-component']].groupby('Timestamp').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636d8f9f-e574-4a87-bb15-9c97bac235d2",
   "metadata": {},
   "source": [
    "# Load Intensity Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "17752dad-c8c1-4f76-9c51-dd17cd0d66c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "brick_kilns = np.load('../source_apportionment/brick_kilns_intensity_80x80.npy')\n",
    "industries = np.load('../source_apportionment/industries_intensity_80x80.npy')\n",
    "power_plants = np.load('../source_apportionment/power_plants_intensity_80x80.npy')\n",
    "population_density = np.load('../source_apportionment/population_density_intensity_80x80.npy')\n",
    "traffic_06 = np.load('../source_apportionment/traffic_06_intensity_80x80.npy')\n",
    "traffic_12 = np.load('../source_apportionment/traffic_12_intensity_80x80.npy')\n",
    "traffic_18 = np.load('../source_apportionment/traffic_18_intensity_80x80.npy')\n",
    "traffic_00 = np.load('../source_apportionment/traffic_00_intensity_80x80.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3c3c873b-80f6-4b9f-a4b7-bfc661490a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap2d(arr: np.ndarray):\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(arr, cmap='viridis', origin='upper')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad7639d-0eb8-4449-85b6-1bd63dd5be17",
   "metadata": {},
   "source": [
    "# GPDM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "edc156a7-7047-45b6-b7c7-986ee768097d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cell_to_cord(i,j,size):\n",
    "    return(j, size-1-i)\n",
    "def cord_to_cell(x,y,size):\n",
    "    return(size-1-y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0c9badcf-94d3-4c2a-8dd9-d97d5c1d4106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpdm_filter(wind_vector, size):\n",
    "    filt = np.zeros((size,size))\n",
    "    dest_i, dest_j = int(size/2), int(size/2)\n",
    "    dest_x, dest_y = cell_to_cord(dest_i, dest_j, size)\n",
    "    for i in range(size):\n",
    "        for j in range(size):\n",
    "            src_i, src_j = i, j\n",
    "            src_x, src_y = cell_to_cord(i,j,size)\n",
    "            unit_wind_vector = wind_vector/np.linalg.norm(wind_vector)\n",
    "            wind_magnitude = np.linalg.norm(wind_vector)\n",
    "            if(dest_x!=src_x or dest_y!=src_y):\n",
    "                distance_vector = np.array([dest_x-src_x, dest_y-src_y])*math.pow(10,3)\n",
    "                dist_wind = np.dot(distance_vector, unit_wind_vector)\n",
    "                if(dist_wind<=0):\n",
    "                    filt[src_i,src_j] = 0\n",
    "                else:\n",
    "                    distance_magnitude = np.linalg.norm(distance_vector)\n",
    "                    dist_per = math.pow(max(math.pow(distance_magnitude,2)-math.pow(dist_wind,2),0),0.5)\n",
    "                    sigma_y = 213*math.pow(dist_wind*0.001,0.894)\n",
    "                    baseline_dist = 707\n",
    "                    dist_wind = max(dist_wind/baseline_dist,1)\n",
    "                    if(dist_per<650):\n",
    "                        filt[src_i,src_j] = 1/((dist_wind**3)*wind_magnitude)\n",
    "                    else:\n",
    "                        filt[src_i,src_j] = 0\n",
    "            else:\n",
    "                filt[src_i,src_j] = 1/(wind_magnitude)        \n",
    "    return(torch.squeeze(torch.tensor(filt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5913bf6f-a34b-4575-8bc9-9ca7a2c64bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wind_vector(ts):\n",
    "    ts = np.array([ts]).astype('datetime64[ns]')[0]\n",
    "    cts = min(df_ws.index, key=lambda x:abs(x-ts))\n",
    "    idx = df_ws.index.to_list().index(cts)\n",
    "    v1 = df_ws.iloc[idx].values\n",
    "    if((cts-ts).total_seconds()>0):\n",
    "        v2 = df_ws.iloc[idx-1].values\n",
    "    else:\n",
    "        v2 = df_ws.iloc[idx+1].values\n",
    "    ws = v1+((v2-v1)*(abs((cts-ts).total_seconds())/(3600*6)))\n",
    "    ws = ws*(5.0/18)\n",
    "    return(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2e8eba88-dcdf-4034-811b-07f10ba0ce90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_filter(ts):\n",
    "    src_radius = 4\n",
    "    wind_vector = get_wind_vector(ts)\n",
    "    ts_filter = gpdm_filter(wind_vector, 2*src_radius+1)\n",
    "    return(ts_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "04a17220-57bb-44ae-9aaa-cddb5d37af8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpdm_at_ts(idx):\n",
    "    ts_filter = compute_filter(idx)\n",
    "    contrib_brick = scipy.signal.convolve2d(brick_kilns, ts_filter, mode='valid')\n",
    "    contrib_industry = scipy.signal.convolve2d(industries, ts_filter, mode='valid')\n",
    "    contrib_pop = scipy.signal.convolve2d(population_density, ts_filter, mode='valid')\n",
    "    if(pd.Timestamp(idx).hour>3 and pd.Timestamp(idx).hour<9):\n",
    "        traffic = traffic_06\n",
    "    elif(pd.Timestamp(idx).hour>=9 and pd.Timestamp(idx).hour<15):\n",
    "        traffic = traffic_12\n",
    "    elif(pd.Timestamp(idx).hour>=15 and pd.Timestamp(idx).hour<21):\n",
    "        traffic = traffic_18\n",
    "    else:\n",
    "        traffic = traffic_00\n",
    "    contrib_traffic = scipy.signal.convolve2d(traffic, ts_filter, mode='valid')    \n",
    "    contributions = np.array([contrib_brick[19:59,16:56], contrib_industry[19:59,16:56], contrib_pop[19:59,16:56], contrib_traffic[19:59,16:56]])\n",
    "    return(contributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7e0d23cb-0211-4f33-a80e-7d7b6662bb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def krig_at_ts(idx):\n",
    "    window_size = 3\n",
    "    i = np.where(np.array(df.index) == idx)[0][0]\n",
    "    df_slice = pd.concat([df[i-window_size:i],df[i+1:i+window_size+1]])\n",
    "    x_win = locs.loc[df.columns]['Longitude'].values\n",
    "    x_win = np.tile(x_win,df_slice.shape[0])\n",
    "    y_win = locs.loc[df.columns]['Latitude'].values\n",
    "    y_win = np.tile(y_win,df_slice.shape[0])    \n",
    "    z_win = np.concatenate([np.arange(i-window_size,i),np.arange(i+1,i+window_size+1)])*0.01\n",
    "    z_win = np.repeat(z_win,len(df.columns))\n",
    "    vals_win = df_slice.values.flatten()\n",
    "    \n",
    "    x_win = x_win[~np.isnan(vals_win)]\n",
    "    y_win = y_win[~np.isnan(vals_win)]\n",
    "    z_win = z_win[~np.isnan(vals_win)]\n",
    "    vals_win = vals_win[~np.isnan(vals_win)]\n",
    "    \n",
    "    x = locs.loc[df.columns]['Longitude'].values\n",
    "    y = locs.loc[df.columns]['Latitude'].values\n",
    "    z = np.ones_like(x)*i*0.01\n",
    "    vals = df.loc[idx].values\n",
    "    cols = np.array(df.columns)[~np.isnan(vals)]\n",
    "    x = x[~np.isnan(vals)]\n",
    "    y = y[~np.isnan(vals)]\n",
    "    z = z[~np.isnan(vals)]\n",
    "    vals = vals[~np.isnan(vals)]\n",
    "\n",
    "    x_train, x_test, y_train, y_test, z_train, z_test, vals_train, vals_test, cols_train, cols_test = train_test_split(\n",
    "        x, y, z, vals, cols, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    x_train = np.concatenate([x_train,x_win])\n",
    "    y_train = np.concatenate([y_train,y_win])\n",
    "    z_train = np.concatenate([z_train,z_win])\n",
    "    vals_train = np.concatenate([vals_train,vals_win])\n",
    "\n",
    "\n",
    "    OK3D = OrdinaryKriging3D(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        z_train,\n",
    "        vals_train,\n",
    "        variogram_model=\"linear\",\n",
    "        verbose=False,\n",
    "        enable_plotting=False,\n",
    "        exact_values=True,\n",
    "    )\n",
    "    \n",
    "    return(OK3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ee6d66cf-822f-474c-b76a-b214199f6503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_row(idx, row):\n",
    "    gpd_concentrations = gpdm_at_ts(idx)\n",
    "    krig_model = krig_at_ts(idx)\n",
    "    # Set up the student teacher network\n",
    "    # vals_pred, ss_pred = OK3D.execute(\"points\", x_test, y_test, z_test)\n",
    "    i = np.where(np.array(df.index) == idx)[0][0]\n",
    "    gridx = np.arange(77.01, 77.40, 0.01)\n",
    "    gridy = np.arange(28.39, 28.78, 0.01)\n",
    "    gridz = i*0.01\n",
    "    krig_vals, krig_std = krig_model.execute(\"grid\", gridx, gridy[::-1], gridz)\n",
    "    y = krig_vals.flatten()\n",
    "    y = np.exp(y)\n",
    "    x = np.zeros((1600,4))\n",
    "    for i in range(4):\n",
    "        x[:,i] = gpd_concentrations[i].flatten()\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(x,y)\n",
    "    return(lr.score(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b56f68eb-e1c7-4d93-a7a4-032fbaa1bdc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3804354430161553\n",
      "None\n",
      "0.12868478911012682\n",
      "None\n",
      "0.08871371898505442\n",
      "None\n",
      "0.12054687150922627\n",
      "None\n",
      "0.24530776808991173\n",
      "None\n",
      "0.2700265028717431\n",
      "None\n",
      "0.259718525753149\n",
      "None\n",
      "0.2670806644468705\n",
      "None\n",
      "0.2595152104811095\n",
      "None\n",
      "0.2674873097754452\n",
      "None\n",
      "0.2934572834610365\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for idx,row in df[4:-4].iterrows():\n",
    "    i+=1\n",
    "    print(process_row(idx,row))\n",
    "    if(i>10):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3871f19-a5a8-4837-bb61-9679a25e1526",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
